---
title: "Self-Study Activities"
previous_title: "Research and Practice Summary"
previous_path: "/ucl/year-2-inquiry-into-developing-quality-pedagogy-and-making-productive-use-of-assessment-part-2/spring-week-2-ect-research-and-practice-summary"
---

## Review: 5 mins

Read the case studies on this week’s topic, or the one that is most relevant to the exploratory question you are investigating. As you read, reflect on:

1. how similar this scenario is to your own situation
2. how, despite any differences there may be to your own context, this case study may still be relevant to you
3. what lessons there might be for the way you conduct your own inquiry

## Plan: 5 mins

### Action planning

Take a few minutes to plan how you will use your self-directed study time this week. Think about:

- what evidence you already have for the way you teach now, and the impact it has on your pupils, e.g.
  - your module audit
  - observation notes from last week
  - the work your pupils are producing
  - what your pupils are saying in class, how they are responding to feedback
- what evidence it would still be useful for you to collect, e.g.
  - the views of your pupils about this change in your practice – how has it altered their attitudes to learning?
  - how the responses of your pupils to the change in your teaching may have altered over time – some may have started well but begun to level off. Can you track that?
  - how the change in your practice is affecting different pupils in different ways
  - the impact of your inquiry on yourself

So, this week you might divide your time between analysing evidence you already have and designing a collection tool for evidence you don’t.

## Theory to Practice: 40 mins

How you collect your evidence will depend upon the area of your practice that you are seeking to improve and the evaluative inquiry question you are asking. However, it is likely to include the following:

### 1. Analyse artefacts and data

Remind yourself of the area of your practice that you are trying to improve and of your evaluative inquiry question, and think again about the sources of evidence that might shed light upon it. These might include ‘artefacts’ such as the following:

- your pupils’ work – whether written, spoken, performed, or created
- your assessment of pieces of work, and your assessment of the pupils over time – and how that compares with other pupils, or expected outcomes
- policy and guidance documents
- lesson plans, curriculum plans, learning resources
- observations by you or of you

It is useful to remember that pupil work – whether it is performed (as in art, drama, music, PE, technology), spoken or written – is a source of evidence. By assessing that work, which you do as a normal part of your professional life, you can bring that evidence to bear on your inquiry question. You should realise that this is work you have already done – not extra work.

School policies and codes of practice are useful artefacts to explore, as are curriculum plans and mark books.

Whether analysing data you already have, or creating an evidence collection tool, it is helpful to bear in mind:

Validity: The sources you analyse will contain much more data than you need for your inquiry. It may be interesting, but don’t be distracted: only collect the evidence that helps answer your question. For example, if you are investigating the boys in a class, look for the data only on them.

Reliability: The data you find might be true for a particular time in the past – is it still true now? For example, is a pupil’s previous learning record reliable evidence of their learning patterns now?

Manageability: Be selective, don’t attempt to analyse all possible sources. Creating codes – for when you spot similar issues arising in different sources – is a handy way to make sense of the data.

Andy asked his TA to keep brief observation notes and discuss them with him at the end of the day; he also took a note of his own observations of the extent to which the pupil grouping intervention was having the desired effect.

Vashti inspected progress data from writing assessments for her own class, and compared this with two other Year 4 classes (which are acting as her control group); she is also keeping a note of her personal reflections.

Louise analysed a summative assessment (and compared this with another of her classes, her control group); she also conducted a book scrutiny of her class’s books with a colleague.

Mo filmed a second lesson to compare it with the first, and likewise watched it back with the Assistant Head for Teaching and Learning; like Louise, he also conducted a book scrutiny of his PE class’s books with a colleague.

All of these methods were manageable and gave them a reliable insight into the emerging effects of the alterations to their practice and their evaluative inquiries.

### 2. Discuss with pupils

Remind yourself of the area of your practice that you are trying to improve and of your evaluative inquiry question and think again about the sources of evidence that might shed light upon it. These might include examples of pupil voice such as the following:

- focus interviews with ‘target’ pupils – you can often do these during a lesson, while others are working independently
- surveys conducted in class (e.g. where you ask pupils to put their hand up if they agree, or they answer a small number of questions instantly)
- when you ‘eavesdrop’ on pupils as they discuss an issue with a partner
- whole class discussion on the issue you want feedback on

When analysing evidence of pupils’ attitudes to learning, or creating a pupil voice evidence collection method, it is helpful to bear these three rules in mind when asking your questions:

Are they valid?

Only ask the questions that you need the answers to for your inquiry.

Are they reliable?

Make sure your pupils understand the questions, and that you understand their answers. Can you trust the answers they give you? Pupils might give you more honest answers if they can do it anonymously. Are you asking the ‘right’ pupils? Try to ensure that they are representative of the group you are interested in. Ask enough pupils, but…

Is it manageable?

Don’t collect more data than you can handle in the time. If you teach 30 pupils, it might be sufficient to ask 5 of them; if you teach 7 classes, you could collect data from one of them. Open questions may give you rich data, but it can be arduous to analyse; closed questions (or ones when you ask pupils to place themselves on a 1-5 scale) are easy to analyse but might tell you less than you wish to know. Some combination of open and closed might be a good way forward for you.

Vashti also carried out individual interviews with each of the 4 target pupils at the start and end of her inquiry (taking 5 minutes each with them, while other pupils worked independently); similarly, Mo interviewed a sample of pupils, including the Pupil Premium girls who were his focus.

Louise carried out a hands-up pupil survey with her experimental class (before and after the half-term), to capture their thoughts on marking, and followed this up with a focus group conversation with a small group of pupils for 10 minutes at lunchtime.

### 3. Self-assessment – making the claim

In preparation for your mentor meeting next week (where you will revisit your Module 8 audit), write a ‘claim’ to describe what the evidence seems to be saying about the impacts of your alteration to practice. This will still not be definitive: there are still some weeks to go before your inquiry is finished. It is useful to get into the habit of evaluating the impact of what you are doing, to help you decide in the future what you will continue to do, what you will do more of, and perhaps what you will stop doing.

If you have been using multiple methods of data collection – however simple – this will strengthen your claim. If you feel something is so, if your pupils say it is so, and if your progress data suggests it is so, then you can make a fairly strong claim.

Not all inquiries lead to positive results. Inquiries that lead to uncertain conclusions are not a waste of time – quite the reverse, such inquiries often generate more questions for further investigation. Disappointing findings can also be incredibly valuable.

Here are the claims made by some of the teachers featured in the case studies.

Vashti:

Through her inquiry, Vashti was learning better how to plan effective lessons, by (4a) using scaffolds for pupils who needed more structure; better how to stimulate her pupils’ thinking, by (4p, 3r) providing scaffolds for talk to increase the focus and rigour of dialogue; and better how to provide frequent opportunities for her pupils, in pairs, to plan, draft and edit their writing. Her claim is:

> Classroom talk, combined with scaffolding resources, can be a powerful
> driver for improving written literacy among pupils with SpLCN in Year 4.

She is going to keep monitoring her use of the ‘speaking sentences’ scaffold.

Louise:

Through experimenting with ‘minimal marking’ as an alternative to always giving full written feedback, she learned better how to reduce the opportunity cost of marking by using codes and verbal feedback (6p). She also learned better how to give whole-class feedback so they knew what they needed to do to improve, and had the time to do it (6h). Her claims therefore are:

> 1. Using codes/verbal feedback does not detrimentally affect pupil progress, compared with a standard written marking approach.

> 2. On average, using codes/verbal feedback saves the teacher about an hour a week, per teaching class, compared with a standard written marking approach.

She will use this insight to now apply the same principles of verbal feedback and minimal marking to her Year 7 and Year 8 classes, while monitoring the impact of that on her pupils and herself.

Mo:

Through expanding his range of questioning approaches, Mo learned better how to include a range of types of questions in class discussions to extend and challenge pupils (4m), provide appropriate wait time between question and response where more developed responses are required (4n), and prompt pupils to elaborate when responding to questioning to check that a correct answer stems from secure understanding (6f). Based on this, his claim is:

> Responsive questioning is a useful tool for improving the quality
> of talk and writing among Pupil Premium girls in Year 11 GCSE PE.

And because he has developed his questioning practice to this extent, Mo has decided to apply the same approaches to his other classroom-based lessons.

## Next Steps: 5 mins

Bring your claim to your mentor meeting next week and be ready to discuss this with them.

In that meeting, you will revisit the audit that you completed at the start of Module 8. To that end, you may also bring other supporting evidence to discuss your progress across Standards 4, 5 and 6.
